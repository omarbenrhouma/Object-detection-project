{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12531c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Desktop/object-detection-video/object_detection_project/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Hard Hat / PPE Detection Dataset - Data Collection and Validation\n",
    "==================================================================\n",
    "This notebook validates and explores the Hard Hat Workers dataset.\n",
    "The dataset contains 3 classes: head, helmet, person\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from collections import Counter\n",
    "import yaml\n",
    "\n",
    "# ==== CONFIGURATION ====\n",
    "PROJECT_ROOT = Path(os.getcwd()).parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "DATA_YAML = DATA_DIR / \"data.yaml\"\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Data YAML exists: {DATA_YAML.exists()}\")\n",
    "\n",
    "# Load dataset configuration\n",
    "if DATA_YAML.exists():\n",
    "    with open(DATA_YAML, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    print(f\"\\nDataset Configuration:\")\n",
    "    print(f\"  Classes: {config.get('nc', 'N/A')}\")\n",
    "    print(f\"  Class names: {config.get('names', [])}\")\n",
    "    print(f\"  Train: {config.get('train', 'N/A')}\")\n",
    "    print(f\"  Val: {config.get('val', 'N/A')}\")\n",
    "    print(f\"  Test: {config.get('test', 'N/A')}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  data.yaml not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfde12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading 5000 samples from COCO-2017 (all classes)...\n",
      "Downloading split 'train' to '/home/omar/fiftyone/coco-2017/train' if necessary\n",
      "Found annotations at '/home/omar/fiftyone/coco-2017/raw/instances_train2017.json'\n",
      "Sufficient images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "You are running the oldest supported major version of MongoDB. Please refer to https://deprecation.voxel51.com for deprecation notices. You can suppress this exception by setting your `database_validation` config parameter to `False`. See https://docs.voxel51.com/user_guide/config.html#configuring-a-mongodb-connection for more information\n",
      "Loading 'coco-2017' split 'train'\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [29.7s elapsed, 0s remaining, 186.3 samples/s]      \n",
      "Dataset 'coco-mini-all-5000' created\n",
      "‚úÖ Dataset 'coco-mini-all' loaded with 5000 samples.\n"
     ]
    }
   ],
   "source": [
    "# ==== STEP 1: Validate Dataset Structure ====\n",
    "from glob import glob\n",
    "\n",
    "IMAGE_EXTS = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}\n",
    "\n",
    "# Check train/val/test splits\n",
    "splits = ['train', 'valid', 'test']\n",
    "dataset_stats = {}\n",
    "\n",
    "for split in splits:\n",
    "    split_dir = DATA_DIR / split\n",
    "    images_dir = split_dir / 'images'\n",
    "    labels_dir = split_dir / 'labels'\n",
    "    \n",
    "    if images_dir.exists():\n",
    "        images = [f for f in images_dir.rglob('*') if f.suffix.lower() in IMAGE_EXTS]\n",
    "        labels = list(labels_dir.rglob('*.txt')) if labels_dir.exists() else []\n",
    "        \n",
    "        dataset_stats[split] = {\n",
    "            'images': len(images),\n",
    "            'labels': len(labels),\n",
    "            'images_dir': images_dir.exists(),\n",
    "            'labels_dir': labels_dir.exists()\n",
    "        }\n",
    "    else:\n",
    "        dataset_stats[split] = {'images': 0, 'labels': 0, 'images_dir': False, 'labels_dir': False}\n",
    "\n",
    "print(\"\\nüìä Dataset Statistics:\")\n",
    "print(\"=\" * 60)\n",
    "for split, stats in dataset_stats.items():\n",
    "    print(f\"{split.upper():10s} | Images: {stats['images']:5d} | Labels: {stats['labels']:5d}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_images = sum(s['images'] for s in dataset_stats.values())\n",
    "total_labels = sum(s['labels'] for s in dataset_stats.values())\n",
    "print(f\"\\nTotal: {total_images} images, {total_labels} labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c76e6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in dataset: 5000\n"
     ]
    }
   ],
   "source": [
    "# ==== STEP 2: Validate Label-Image Pairs ====\n",
    "import re\n",
    "\n",
    "def parse_yolo_label(path):\n",
    "    \"\"\"Parse YOLO label file and return class counts.\"\"\"\n",
    "    classes = []\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                parts = re.split(r'\\s+', line)\n",
    "                if len(parts) >= 5:\n",
    "                    cls_id = int(parts[0])\n",
    "                    classes.append(cls_id)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {path}: {e}\")\n",
    "    return classes\n",
    "\n",
    "# Check label-image pairs and class distribution\n",
    "class_counts = Counter()\n",
    "missing_labels = []\n",
    "missing_images = []\n",
    "\n",
    "for split in splits:\n",
    "    split_dir = DATA_DIR / split\n",
    "    images_dir = split_dir / 'images'\n",
    "    labels_dir = split_dir / 'labels'\n",
    "    \n",
    "    if not images_dir.exists() or not labels_dir.exists():\n",
    "        continue\n",
    "    \n",
    "    # Get all images and labels\n",
    "    images = {f.stem: f for f in images_dir.rglob('*') if f.suffix.lower() in IMAGE_EXTS}\n",
    "    labels = {f.stem: f for f in labels_dir.rglob('*.txt')}\n",
    "    \n",
    "    # Check pairs\n",
    "    for stem, img_path in images.items():\n",
    "        if stem not in labels:\n",
    "            missing_labels.append((split, stem))\n",
    "    \n",
    "    for stem, lbl_path in labels.items():\n",
    "        if stem not in images:\n",
    "            missing_images.append((split, stem))\n",
    "        else:\n",
    "            # Count classes in this label\n",
    "            classes = parse_yolo_label(lbl_path)\n",
    "            class_counts.update(classes)\n",
    "\n",
    "print(f\"\\n‚úÖ Label-Image Pair Validation:\")\n",
    "print(f\"  Missing labels: {len(missing_labels)}\")\n",
    "print(f\"  Missing images: {len(missing_images)}\")\n",
    "\n",
    "if missing_labels:\n",
    "    print(f\"\\n‚ö†Ô∏è  Images without labels (first 5):\")\n",
    "    for split, stem in missing_labels[:5]:\n",
    "        print(f\"    {split}/{stem}\")\n",
    "\n",
    "if missing_images:\n",
    "    print(f\"\\n‚ö†Ô∏è  Labels without images (first 5):\")\n",
    "    for split, stem in missing_images[:5]:\n",
    "        print(f\"    {split}/{stem}\")\n",
    "\n",
    "# Class distribution\n",
    "class_names = config.get('names', ['head', 'helmet', 'person'])\n",
    "print(f\"\\nüìà Class Distribution:\")\n",
    "for cls_id, count in sorted(class_counts.items()):\n",
    "    cls_name = class_names[cls_id] if cls_id < len(class_names) else f\"class_{cls_id}\"\n",
    "    print(f\"  {cls_name:10s} (ID {cls_id}): {count:6d} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f5a510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Exporting to YOLO format...\n",
      "Directory '/home/omar/Desktop/object-detection-video/object_detection_project/data/yolo_dataset' already exists; export will be merged with existing files\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [15.5s elapsed, 0s remaining, 345.7 samples/s]      \n",
      "‚úÖ Export complete!\n",
      "Your dataset is ready at: /home/omar/Desktop/object-detection-video/object_detection_project/data/yolo_dataset\n"
     ]
    }
   ],
   "source": [
    "# ==== STEP 3: Sample Visualization ====\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def yolo_to_xyxy(x, y, w, h, img_w, img_h):\n",
    "    \"\"\"Convert YOLO format to xyxy coordinates.\"\"\"\n",
    "    cx = x * img_w\n",
    "    cy = y * img_h\n",
    "    bw = w * img_w\n",
    "    bh = h * img_h\n",
    "    x1 = int(max(0, cx - bw / 2))\n",
    "    y1 = int(max(0, cy - bh / 2))\n",
    "    x2 = int(min(img_w - 1, cx + bw / 2))\n",
    "    y2 = int(min(img_h - 1, cy + bh / 2))\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "# Visualize a few random samples\n",
    "num_samples = 4\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "samples_shown = 0\n",
    "for split in splits:\n",
    "    if samples_shown >= num_samples:\n",
    "        break\n",
    "    \n",
    "    split_dir = DATA_DIR / split\n",
    "    images_dir = split_dir / 'images'\n",
    "    labels_dir = split_dir / 'labels'\n",
    "    \n",
    "    if not images_dir.exists():\n",
    "        continue\n",
    "    \n",
    "    images = [f for f in images_dir.rglob('*') if f.suffix.lower() in IMAGE_EXTS]\n",
    "    if not images:\n",
    "        continue\n",
    "    \n",
    "    # Sample random image\n",
    "    sample_img = random.choice(images)\n",
    "    sample_lbl = labels_dir / f\"{sample_img.stem}.txt\"\n",
    "    \n",
    "    if not sample_lbl.exists():\n",
    "        continue\n",
    "    \n",
    "    # Load and display\n",
    "    img = Image.open(sample_img).convert('RGB')\n",
    "    img_w, img_h = img.size\n",
    "    \n",
    "    ax = axes[samples_shown]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"{split.upper()}: {sample_img.name}\", fontsize=10)\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    with open(sample_lbl, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = re.split(r'\\s+', line)\n",
    "            if len(parts) >= 5:\n",
    "                cls_id = int(parts[0])\n",
    "                x, y, w, h = map(float, parts[1:5])\n",
    "                x1, y1, x2, y2 = yolo_to_xyxy(x, y, w, h, img_w, img_h)\n",
    "                \n",
    "                cls_name = class_names[cls_id] if cls_id < len(class_names) else f\"class_{cls_id}\"\n",
    "                color = 'lime' if cls_id == 1 else ('red' if cls_id == 0 else 'cyan')\n",
    "                \n",
    "                rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, \n",
    "                                    edgecolor=color, linewidth=2)\n",
    "                ax.add_patch(rect)\n",
    "                ax.text(x1, y1-5, cls_name, color='white', fontsize=8,\n",
    "                       bbox=dict(facecolor=color, alpha=0.7, pad=2))\n",
    "    \n",
    "    ax.axis('off')\n",
    "    samples_shown += 1\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(samples_shown, num_samples):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset validation complete!\")\n",
    "print(f\"   Ready for training with {total_images} images across {len(splits)} splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f410ca28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples loaded in FiftyOne dataset: 5000\n"
     ]
    }
   ],
   "source": [
    "# ==== STEP 4: Dataset Summary ====\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATASET SUMMARY - Hard Hat / PPE Detection\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Classes: {', '.join(class_names)}\")\n",
    "print(f\"Total images: {total_images}\")\n",
    "print(f\"Total labels: {total_labels}\")\n",
    "print(f\"\\nSplit distribution:\")\n",
    "for split, stats in dataset_stats.items():\n",
    "    pct = (stats['images'] / total_images * 100) if total_images > 0 else 0\n",
    "    print(f\"  {split:10s}: {stats['images']:5d} images ({pct:5.1f}%)\")\n",
    "print(\"\\n‚úÖ Dataset is ready for training!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a6a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=926425de-773e-4be4-89a2-f227742302c0\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x745d7b99be00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook sessions cannot wait\n"
     ]
    }
   ],
   "source": [
    "# ==== STEP 5: Verify YOLO Format Compatibility ====\n",
    "print(\"\\nüîç Verifying YOLO format compatibility...\")\n",
    "\n",
    "# Check a few label files\n",
    "sample_checked = 0\n",
    "for split in splits:\n",
    "    if sample_checked >= 3:\n",
    "        break\n",
    "    \n",
    "    split_dir = DATA_DIR / split\n",
    "    labels_dir = split_dir / 'labels'\n",
    "    \n",
    "    if not labels_dir.exists():\n",
    "        continue\n",
    "    \n",
    "    labels = list(labels_dir.rglob('*.txt'))\n",
    "    if not labels:\n",
    "        continue\n",
    "    \n",
    "    sample_lbl = random.choice(labels)\n",
    "    with open(sample_lbl, 'r') as f:\n",
    "        lines = [l.strip() for l in f.readlines() if l.strip()]\n",
    "        if lines:\n",
    "            parts = re.split(r'\\s+', lines[0])\n",
    "            if len(parts) >= 5:\n",
    "                cls_id = int(parts[0])\n",
    "                coords = list(map(float, parts[1:5]))\n",
    "                if all(0 <= c <= 1 for c in coords[1:]) and 0 <= coords[0] < 1:\n",
    "                    print(f\"  ‚úÖ {split}/{sample_lbl.name}: Valid YOLO format\")\n",
    "                    sample_checked += 1\n",
    "                else:\n",
    "                    print(f\"  ‚ö†Ô∏è  {split}/{sample_lbl.name}: Coordinates out of range\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå {split}/{sample_lbl.name}: Invalid format\")\n",
    "\n",
    "print(\"\\n‚úÖ Dataset format validation complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
